% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_evaluate.R
\name{precision}
\alias{precision}
\title{Precision}
\usage{
precision(pred, true)
}
\arguments{
\item{pred}{vector of predicted labels derived from some model, such as \link{textmodel_mlp},
which is being subjected to evaluation}

\item{true}{a vector of known labels that are used to evaluate model performance}
}
\description{
\code{precision()} Implements a function that calculates the precision, also known as the positive predictive value, of labels predicted by a machine learning model and a vector of true values.
It is calculated by calculating the ratio of true predicted positives to total predicted positives. Its values range from 0 to 1, where 0 would indicate that no predicted positives were true positives
and 1 would indicate that all predicted positives were true positives.
}
\seealso{
\code{\link[=textmodel_evaluate]{textmodel_evaluate()}}
}
