% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_evaluate.R
\name{textmodel_evaluate}
\alias{textmodel_evaluate}
\title{Model evaluation function}
\usage{
textmodel_evaluate(
  x,
  y,
  model,
  fun = "f1_score",
  k = 5,
  parameters = list(),
  seed = as.numeric(Sys.time()),
  time = TRUE
)
}
\arguments{
\item{x}{the \link{dfm} or \link{tokens} object on which the model will be fit.  Does not need to
contain only the training documents.}

\item{y}{vector of training labels associated with each document identified
in \code{train}.  (These will be converted to factors if not already
factors.)}

\item{model}{the name of the machine learning function that will be evaluated}

\item{fun}{the name of the function that will be used to evaluate the machine learning model.
For example, accuracy, precision, recall, or f1_score}

\item{k}{number of folds}

\item{parameters}{model hyperparameters}

\item{seed}{a seed that can allow for replication of k training data splits.
If seed is not provided a seed is chosen based on the current time.}

\item{time}{a logical parameter that determines whether output will include training
time (in seconds) of model}
}
\description{
Designed to streamline the parameter tuning and evaluation process.
Users chose a function to evaluate and include parameter values as a list.
If multiple parameter values are provided, the function will estimate a separate
model for every combination of parameters.
}
\examples{
# evaluate immigration classification performance
\dontrun{
dfmat <- dfm(data_corpus_manifestosentsUK)
codes <- docvars(data_corpus_manifestosentsUK, "crowd_immigration_label")
evaluation <- textmodel_evaluate(dfmat, codes, k = 3, model = "textmodel_mlp", fun = "f1_score",
  parameters = list(epochs = c(3, 4)))

head(evaluation)
aggregate(evaluation, by = list(evaluation$cost), FUN = "mean")
}
}
