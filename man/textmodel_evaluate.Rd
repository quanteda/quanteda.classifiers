% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel_evaluate.R
\name{textmodel_evaluate}
\alias{textmodel_evaluate}
\title{Model evaluation function}
\usage{
textmodel_evaluate(
  x,
  y,
  model,
  fun = "f1_score",
  k = 5,
  parameters = list(),
  parameters_fixed = list(),
  seed = as.numeric(Sys.time()),
  time = TRUE,
  by_class = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{x}{the \link{dfm}, \link{tokens}, or \link{tokens2sequences} object on which the model will be
fit.  Does not need to contain only the training documents.}

\item{y}{vector of training labels associated with each document identified
in \code{train}.  (These will be converted to factors if not already
factors.)}

\item{model}{the name of the machine learning function that will be evaluated}

\item{fun}{the name of the function that will be used to evaluate the machine
learning model. Can take the values "accuracy", "precision", "recall", or
"f1_score"}

\item{k}{number of folds}

\item{parameters}{model hyperparameters that vary across model iterations}

\item{parameters_fixed}{model hyperparameters that are held constant across
model iterations}

\item{seed}{a seed that can allow for replication of k training data splits.
If seed is not provided a seed is chosen based on the current time.}

\item{time}{a logical parameter that determines whether output will include
training time (in seconds) of model}

\item{by_class}{estimates a separate value of provided evaluation function
for every class of the true vector}

\item{verbose}{Boolean parameter that determines whether the model provides
updates regarding model-fitting progress}
}
\description{
Designed to streamline the parameter tuning and evaluation process. Users
chose a function to evaluate and include parameter values as a list. If
multiple parameter values are provided, the function will perform a grid
search by estimating a separate model for every combination of parameters.
}
\examples{
# evaluate immigration classification performance
\dontrun{
dfmat <- dfm(data_corpus_manifestosentsUK)
codes <- docvars(data_corpus_manifestosentsUK, "crowd_immigration_label")
evaluation <- textmodel_evaluate(dfmat, codes, k = 3,
                                 model = "textmodel_mlp", fun = "f1_score",
                                 parameters = list(epochs = c(3, 4)))
head(evaluation)
aggregate(evaluation, by = list(evaluation$cost), FUN = "mean")
}
}
